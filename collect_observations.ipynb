{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "collect_observations.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ud1imNjOg4P",
        "colab_type": "text"
      },
      "source": [
        "## Collecting data from the enviroment for each observation and action record the reward\n",
        "- 1/10 of the data comes from random agent\n",
        "- rest from individual after 1000 epochs of CEM algorithm with some noise to it's actions\n",
        "Noise come from $N(0, s)$ where s is from $Uniform(0.1)$. Action space is $[-1, 1]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LETKu5BZsgqh",
        "colab_type": "text"
      },
      "source": [
        "Some other tried:\n",
        "- equally from all individuals (0 -> 950)\n",
        "- all random\n",
        "- 1/25 from random, rest from best with noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyT5HsMQXbH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "1c0af412-c259-4ab8-ffdc-cf1205149e59"
      },
      "source": [
        "!pip install pybullet==2.5.5\n",
        "\n",
        "%cd /usr/local/lib/python3.6/dist-packages\n",
        "!git clone https://github.com/benelot/pybullet-gym.git\n",
        "%cd pybullet-gym\n",
        "!pip install -e .\n",
        "%cd\n",
        "%cd ../content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pybullet==2.5.5\n",
            "  Using cached https://files.pythonhosted.org/packages/d4/6c/6b14ae6d1d8f10f16ea82c2c194394564b02c80b88b6e391470046968c7b/pybullet-2.5.5.tar.gz\n",
            "Building wheels for collected packages: pybullet\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybullet: filename=pybullet-2.5.5-cp36-cp36m-linux_x86_64.whl size=71822342 sha256=34dcfa2b4b23654149ed470ba8c8cc00b7060ca69d9e76cca5f71e2b0ad0bd4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/e4/cc/7b50d6689e1bc6ba07d2df04946a0eabc89deca7caed5f52d1\n",
            "Successfully built pybullet\n",
            "Installing collected packages: pybullet\n",
            "Successfully installed pybullet-2.5.5\n",
            "/usr/local/lib/python3.6/dist-packages\n",
            "Cloning into 'pybullet-gym'...\n",
            "remote: Enumerating objects: 735, done.\u001b[K\n",
            "remote: Total 735 (delta 0), reused 0 (delta 0), pack-reused 735\u001b[K\n",
            "Receiving objects: 100% (735/735), 19.29 MiB | 19.11 MiB/s, done.\n",
            "Resolving deltas: 100% (405/405), done.\n",
            "/usr/local/lib/python3.6/dist-packages/pybullet-gym\n",
            "Obtaining file:///usr/local/lib/python3.6/dist-packages/pybullet-gym\n",
            "Requirement already satisfied: pybullet>=1.7.8 in /usr/local/lib/python3.6/dist-packages (from pybulletgym==0.1) (2.5.5)\n",
            "Installing collected packages: pybulletgym\n",
            "  Running setup.py develop for pybulletgym\n",
            "Successfully installed pybulletgym\n",
            "/root\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRSFkATk44y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "\n",
        "import gym\n",
        "import pybulletgym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7gSEQBy4yJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA = torch.cuda.is_available()\n",
        "\n",
        "def to_np(x):\n",
        "    return x.detach().cpu().numpy()\n",
        "\n",
        "def to_tensor(x, requires_grad=False):\n",
        "    x = torch.from_numpy(x)\n",
        "    if CUDA:\n",
        "        x = x.cuda()\n",
        "    \n",
        "    if requires_grad:\n",
        "        return x.clone().contiguous().detach().requires_grad_(True)\n",
        "    else:\n",
        "        return x.clone().contiguous().detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjDZf6JhMyVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AgentNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(AgentNetwork, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(111, 100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 8),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = X.view(X.size(0), -1)\n",
        "        return self.layers.forward(X)\n",
        "    \n",
        "    \n",
        "    def set_params(self, params):\n",
        "        cpt = 0\n",
        "        for param in self.parameters():\n",
        "            tmp = np.product(param.size())\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                param.data.copy_(to_tensor(\n",
        "                    params[cpt:cpt + tmp]).view(param.size()).cuda())\n",
        "            else:\n",
        "                param.data.copy_(to_tensor(\n",
        "                    params[cpt:cpt + tmp]).view(param.size()))\n",
        "            cpt += tmp\n",
        "\n",
        "            \n",
        "    def get_params(self):\n",
        "        return deepcopy(np.hstack([to_np(v).flatten() for v in\n",
        "                                   self.parameters()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxGDnJ8s5inV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm, trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZBXO_BhpZg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_with_noise():\n",
        "    X, Y = [], []\n",
        "\n",
        "    goal = 2500000\n",
        "    pbar = tqdm(total=goal,position=0, leave=True)\n",
        "\n",
        "    env = gym.make('AntMuJoCoEnv-v0')\n",
        "\n",
        "    # let 1/10 be from random actions\n",
        "    while len(Y) < 250000:\n",
        "        try:\n",
        "            observation = env.reset()\n",
        "\n",
        "            for _ in range(1000):\n",
        "                env.render()\n",
        "                \n",
        "                action = env.action_space.sample() \n",
        "                    \n",
        "                X.append(list(observation)+list(action))\n",
        "\n",
        "                observation, reward, done, info = env.step(action)\n",
        "\n",
        "                Y.append(reward)\n",
        "\n",
        "                if done: \n",
        "                    break;\n",
        "                        \n",
        "            pbar.update(_)\n",
        "        except:\n",
        "            env.close()\n",
        "            env = gym.make('AntMuJoCoEnv-v0')\n",
        "\n",
        "\n",
        "    # rest from good individual with some noise to actions\n",
        "    ind = pickle.load(open(f'drive/My Drive/project_evo/history/try1/950.pkl', 'rb'))['best']\n",
        "    actor = AgentNetwork()\n",
        "    actor.set_params(ind)\n",
        "\n",
        "    \n",
        "    while len(Y) < goal:\n",
        "        try:\n",
        "            observation = env.reset()\n",
        "            l_obs = observation\n",
        "\n",
        "            observation = to_tensor(observation.reshape(1, -1).astype(np.float32))\n",
        "\n",
        "            for _ in range(10000):\n",
        "                env.render()\n",
        "                action = actor(observation)\n",
        "                action = to_np(action)[0]\n",
        "\n",
        "                action += np.clip(np.random.normal(0, np.random.random(8)/10), -1, 1)\n",
        "\n",
        "                X.append(list(l_obs)+list(action))\n",
        "                \n",
        "                observation, reward, done, info = env.step(action)\n",
        "                l_obs = observation\n",
        "                observation = to_tensor(observation.reshape(1, -1).astype(np.float32))\n",
        "\n",
        "                Y.append(reward)\n",
        "\n",
        "                if done: \n",
        "                    break\n",
        "            pbar.update(_)\n",
        "        except:\n",
        "            env.close()\n",
        "            env = gym.make('AntMuJoCoEnv-v0')\n",
        "            \n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    env.close()\n",
        "    return np.array(X), np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wOL5G4arjaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c28e9fb1-2af7-48f3-cf49-112f0e4fba52"
      },
      "source": [
        "X, Y = collect_with_noise()\n",
        "\n",
        "pickle.dump({'X': X, 'Y': Y}, open('drive/My Drive/project_evo/data.pkl', 'w+b'), pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2500000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "current_dir=/usr/local/lib/python3.6/dist-packages/pybullet_envs/bullet\n",
            "WalkerBase::__init__\n",
            "options= \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 2497500/2500000 [1:30:35<00:05, 459.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhqJygjg5_sD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0303ae8a-43e9-429e-ed96-954692040486"
      },
      "source": [
        "B_NO = 10\n",
        "in_b = int(2000000/B_NO)\n",
        "for b in trange(B_NO, position=0):\n",
        "    bx, by = X[b*in_b:(b+1)*in_b], Y[b*in_b:(b+1)*in_b]\n",
        "    pickle.dump({'X': to_tensor(bx.astype(np.float32)), 'Y': to_tensor(by.reshape(-1, 1))}, \n",
        "                open(f'drive/My Drive/project_evo/data/b{b}.pkl', 'w+b'),\n",
        "                pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
            "100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeRAhZ-aEGqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}